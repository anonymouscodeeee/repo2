{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoModel,\n",
    "    AutoModelForSequenceClassification, \n",
    "    Trainer,TrainingArguments,EvalPrediction,\n",
    "    RobertaForSequenceClassification,        \n",
    "    RobertaModel,\n",
    "    RobertaConfig,\n",
    "    FlaxRobertaForSequenceClassification,\n",
    "    )\n",
    "import pandas  as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../codebert-base\")\n",
    "\n",
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    '../codebert-base',\n",
    "    num_labels=2, \n",
    "    problem_type=\"single_label_classification\",\n",
    ")\n",
    "for param in model.roberta.parameters():\n",
    "    param.requires_grad=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"./MSR_data_cleaned.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "def process_data(df):\n",
    "    df.iloc[0]\n",
    "    funcs_len = [len(f) for f in df.func_before]\n",
    "    df[\"func_len\"] = funcs_len\n",
    "\n",
    "    df_short = df[(df.func_len>50)&(df.func_len<tokenizer.model_max_length)]\n",
    "    df_vul = df_short[df_short.vul==1]\n",
    "    df_novul = df_short[df_short.vul==0].sample(len(df_vul))\n",
    "    df_sample = pd.concat([df_vul,df_novul])\n",
    "    df_sample = df_sample.sample(frac=1)[[\"func_before\", \"vul\"]]\n",
    "    df_sample.reset_index(drop=True)\n",
    "    return df_sample\n",
    "\n",
    "df_sample = process_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "def tokenize(df,tokenizer):\n",
    "    input_ids = []\n",
    "    masks=[]\n",
    "    for i in tqdm.tqdm(range(0,len(df),64)):\n",
    "        res = tokenizer(df.func_before.to_list()[i:min(i+64, len(df))], padding=\"max_length\", truncation=True,return_tensors=\"pt\")\n",
    "        input_ids.extend(res[\"input_ids\"])\n",
    "        masks.extend(res[\"attention_mask\"])\n",
    "    df_tokenized = df.copy()\n",
    "    df_tokenized[\"input_ids\"] = input_ids\n",
    "    df_tokenized[\"attention_mask\"]=masks\n",
    "    return df_tokenized\n",
    "\n",
    "def split_data(df):\n",
    "    df_train, df_other = train_test_split(df, test_size=0.2, stratify=df_sample['vul'])\n",
    "    df_val,df_test = train_test_split(df_other, test_size=0.5,  stratify=df_other['vul'])\n",
    "    return df_train,df_val,df_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = tokenize(df_sample,tokenizer)\n",
    "df_train,df_val,df_test = split_data(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,precision_recall_fscore_support\n",
    "class DetectDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.funcs = df.input_ids.to_list()\n",
    "        self.masks=df.attention_mask.to_list()\n",
    "        self.labels = df.vul.to_list()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self,i):          \n",
    "        return {\n",
    "            'input_ids': self.funcs[i],           \n",
    "            'labels':  torch.tensor(self.labels[i],dtype=torch.long),\n",
    "            'attention_mask':self.masks[i],\n",
    "        }\n",
    "    \n",
    "    def len(self):\n",
    "        return self.__len__()\n",
    "    \n",
    "    def getitem(self,i):\n",
    "        return self.__getitem__(i)\n",
    "        \n",
    "\n",
    "def my_compute_metrics(pred:EvalPrediction):\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(pred.label_ids, preds, average='binary', zero_division=0.0)\n",
    "    acc = accuracy_score(pred.label_ids, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f-score': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "def test(model_test, data):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    loader = DataLoader(dataset=DetectDataset(df=data),batch_size=128)\n",
    "    model_test = model_test.to(device)\n",
    "    labels = []\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for _, batch in tqdm.tqdm(enumerate(loader)):  \n",
    "            batch[\"input_ids\"] = torch.mul(batch[\"input_ids\"], batch[\"attention_mask\"]).to(device)   \n",
    "            batch[\"attention_mask\"] = batch[\"attention_mask\"].to(device) \n",
    "            labels.extend(batch[\"labels\"].tolist())\n",
    "            del batch[\"labels\"]             \n",
    "            outputs = model_test(**batch)\n",
    "            pred= outputs[\"logits\"].cpu().argmax(-1).tolist()\n",
    "            preds.extend(pred)\n",
    "\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0.0)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "\n",
    "    print(f\"test reulsts: acc {acc}, f1 {f1},  precision {precision}, recall {recall} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./output\",  # output directory\n",
    "    num_train_epochs=30,  # total number of training epochs\n",
    "    per_device_train_batch_size=128,  # batch size per device during training\n",
    "    per_device_eval_batch_size=256,  # batch size for evaluation\n",
    "    warmup_steps=500,  # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.001,  # strength of weight decay\n",
    "    logging_dir=\"./logs\",  # directory for storing logs\n",
    "    logging_steps=10,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=10,\n",
    "    learning_rate=1e-3,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=0.05,\n",
    ")\n",
    "\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model, \n",
    "    train_dataset=DetectDataset(df_train), \n",
    "    eval_dataset=DetectDataset(df_val),\n",
    "    compute_metrics=my_compute_metrics,\n",
    "    args=training_args,  \n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(model,df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(df_train,df_val,df_test):\n",
    "    df_1 = df_train.drop([\"input_ids\", \"attention_mask\"],axis=1)\n",
    "    df_2 = df_val.drop([\"input_ids\", \"attention_mask\"],axis=1)\n",
    "    df_3 = df_test.drop([\"input_ids\", \"attention_mask\"],axis=1)\n",
    "\n",
    "    df_1[\"split\"]=[\"train\"]*len(df_1)\n",
    "    df_2[\"split\"]=[\"val\"]*len(df_2)\n",
    "    df_3[\"split\"]=[\"test\"]*len(df_3)\n",
    "\n",
    "    df_save = pd.concat([df_1, df_2,df_3])\n",
    "    df_save.reset_index(inplace=True)\n",
    "\n",
    "    df_save.to_csv(\"./msr.csv\",index=False)\n",
    "    \n",
    "save_data(df_train, df_val,df_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./checkpoint\")\n",
    "tokenizer.save_pretrained(\"./checkpoint\")\n",
    "flax_model = FlaxRobertaForSequenceClassification.from_pretrained('./checkpoint', from_pt=True)\n",
    "flax_model.save_pretrained('./checkpoint', use_msgpack=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"./checkpoint\")\n",
    "model = RobertaForSequenceClassification.from_pretrained(\"./checkpoint\")\n",
    "\n",
    "df_msr = pd.read_csv(\"./checkpoint/msr.csv\")\n",
    "df_1 = df_msr[df_msr[\"split\"]==\"test\"]\n",
    "df_1 = tokenize(df_1,tokenizer)\n",
    "\n",
    "test(model,df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1[\"len\"] = [len(f) for f in df_1.func_before]\n",
    "df_1.len.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = df_1[df_1.len<400]\n",
    "test(model,df_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flax_model1 = FlaxRobertaForSequenceClassification.from_pretrained('./checkpoint1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_msr = pd.read_csv(\"./checkpoint/msr.csv\")\n",
    "df_1 = df_msr[df_msr[\"split\"]==\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = df_sample.copy()\n",
    "df_tt[\"len\"] = [len(f) for f in df_tt.func_before]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(df_tt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
